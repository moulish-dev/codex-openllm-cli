# Codex-LLM ðŸ§ 
A lightweight, pluggable CLI coding assistant that supports both local and remote LLMs (Ollama, OpenAI, and more).

# Challenges

[] Removed OpenAI API key dependency
[] Integrated Ollama client
[] Stubbed out model checks
[] CLI prints output with -f
[] Refactor AgentLoop.ts to remove OpenAI dependency
[] Define and use custom ResponseItem types
[] Adapt UI handlers to work with raw string (or fake streaming)